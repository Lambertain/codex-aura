name: 'Codex Aura Analyze'
description: 'Analyze codebase and generate dependency graph'
branding:
  icon: 'git-branch'
  color: 'purple'

inputs:
  path:
    description: 'Path to analyze (deprecated: use paths for monorepo support)'
    required: false
    default: '.'
  paths:
    description: 'Paths to analyze (one per line for monorepo support)'
    required: false
  edge-types:
    description: 'Edge types to extract'
    required: false
    default: 'imports,calls,extends'
  output:
    description: 'Output file path'
    required: false
    default: 'codex-aura-graph.json'
  comment-on-pr:
    description: 'Add comment to PR with results'
    required: false
    default: 'false'
  fail-on-risk:
    description: 'Risk level to fail on (low/medium/high/critical/none)'
    required: false
    default: 'none'
  upload-artifact:
    description: 'Upload graph as artifact'
    required: false
    default: 'false'
  artifact-name:
    description: 'Name for the uploaded artifact'
    required: false
    default: 'codex-aura-graph'
  artifact-retention-days:
    description: 'Retention days for artifact'
    required: false
    default: '30'
  track-metrics:
    description: 'Track metrics for trend analysis'
    required: false
    default: 'false'
  cross-package-deps:
    description: 'Analyze dependencies between packages in monorepo'
    required: false
    default: 'false'

outputs:
  graph-file:
    description: 'Path to generated graph file'
  node-count:
    description: 'Number of nodes in graph'
  edge-count:
    description: 'Number of edges in graph'
  average-complexity:
    description: 'Average complexity score'
  hot-spots-count:
    description: 'Number of hot spots detected'

runs:
  using: 'composite'
  steps:
    - name: Install Codex Aura
      run: pip install codex-aura
      shell: bash

    - name: Analyze codebase
      id: analyze
      run: |
        # Determine paths to analyze
        if [ -n "${{ inputs.paths }}" ]; then
          # Use multiline paths input for monorepo
          PATHS="${{ inputs.paths }}"
        else
          # Fallback to single path (backward compatibility)
          PATHS="${{ inputs.path }}"
        fi

        # Convert multiline to array
        IFS=$'\n' read -r -d '' -a PATH_ARRAY <<< "$PATHS"

        # Analyze each path
        COMBINED_GRAPH="{}"
        PACKAGE_RESULTS="[]"

        for path in "${PATH_ARRAY[@]}"; do
          if [ -z "$path" ]; then continue; fi

          echo "Analyzing path: $path"

          # Generate unique output file for each package
          PACKAGE_OUTPUT="${{ inputs.output }}.$(basename "$path" | tr '/' '_').json"

          # Run analysis for this package
          codex-aura analyze "$path" \
            --edges "${{ inputs.edge-types }}" \
            --format json \
            --output "$PACKAGE_OUTPUT"

          # Store package result
          PACKAGE_RESULTS=$(echo "$PACKAGE_RESULTS" | jq --arg path "$path" --arg output "$PACKAGE_OUTPUT" '. + [{"path": $path, "output": $output}]')

          # Merge graphs if cross-package-deps is enabled
          if [ "${{ inputs.cross-package-deps }}" = "true" ]; then
            if [ "$COMBINED_GRAPH" = "{}" ]; then
              COMBINED_GRAPH=$(cat "$PACKAGE_OUTPUT")
            else
              # Merge nodes and edges (simplified merge)
              COMBINED_GRAPH=$(jq -s '.[0] as $g1 | .[1] as $g2 | {
                repository: $g1.repository,
                version: $g1.version,
                generated_at: $g1.generated_at,
                nodes: ($g1.nodes + $g2.nodes),
                edges: ($g1.edges + $g2.edges),
                stats: {
                  total_nodes: ($g1.stats.total_nodes + $g2.stats.total_nodes),
                  total_edges: ($g1.stats.total_edges + $g2.stats.total_edges),
                  node_types: ($g1.stats.node_types + $g2.stats.node_types),
                  average_complexity: ((($g1.stats.average_complexity // 0) + ($g2.stats.average_complexity // 0)) / 2),
                  hot_spots_count: (($g1.stats.hot_spots_count // 0) + ($g2.stats.hot_spots_count // 0))
                }
              }' <(echo "$COMBINED_GRAPH") "$PACKAGE_OUTPUT")
            fi
          fi
        done

        # Save combined graph if cross-package-deps enabled, otherwise use first package
        if [ "${{ inputs.cross-package-deps }}" = "true" ]; then
          echo "$COMBINED_GRAPH" > "${{ inputs.output }}"
        else
          # Copy first package output as main output
          FIRST_OUTPUT=$(echo "$PACKAGE_RESULTS" | jq -r '.[0].output')
          if [ -n "$FIRST_OUTPUT" ] && [ "$FIRST_OUTPUT" != "null" ]; then
            cp "$FIRST_OUTPUT" "${{ inputs.output }}"
          fi
        fi

        # Save package results for later use
        echo "$PACKAGE_RESULTS" > package_results.json
      shell: bash

    - name: Set outputs
      id: outputs
      run: |
        NODE_COUNT=$(jq '.stats.total_nodes' "${{ inputs.output }}")
        EDGE_COUNT=$(jq '.stats.total_edges' "${{ inputs.output }}")
        AVG_COMPLEXITY=$(jq '.stats.average_complexity // 0' "${{ inputs.output }}")
        HOT_SPOTS=$(jq '.stats.hot_spots_count // 0' "${{ inputs.output }}")

        echo "graph-file=${{ inputs.output }}" >> $GITHUB_OUTPUT
        echo "node-count=$NODE_COUNT" >> $GITHUB_OUTPUT
        echo "edge-count=$EDGE_COUNT" >> $GITHUB_OUTPUT
        echo "average-complexity=$AVG_COMPLEXITY" >> $GITHUB_OUTPUT
        echo "hot-spots-count=$HOT_SPOTS" >> $GITHUB_OUTPUT

        echo "‚úÖ Analysis complete: $NODE_COUNT nodes, $EDGE_COUNT edges"
      shell: bash

    - name: Calculate impact analysis
      id: impact
      if: inputs.comment-on-pr == 'true' || inputs.fail-on-risk != 'none' || inputs.track-metrics == 'true'
      run: |
        # Get PR number from event if available
        if [ -f "$GITHUB_EVENT_PATH" ]; then
          PR_NUMBER=$(jq -r '.number // empty' "$GITHUB_EVENT_PATH")
        fi

        if [ -n "$PR_NUMBER" ] && [ "$PR_NUMBER" != "null" ]; then
          # Get changed files from PR
          CHANGED_FILES=$(curl -s \
            -H "Authorization: token ${{ github.token }}" \
            -H "Accept: application/vnd.github.v3+json" \
            "https://api.github.com/repos/${{ github.repository }}/pulls/$PR_NUMBER/files" | \
            jq -r '.[].filename' | tr '\n' ' ')

          echo "Changed files: $CHANGED_FILES"
        else
          CHANGED_FILES=""
        fi

        # Calculate impact analysis using Python script
        IMPACT_DATA=$(python3 -c "
        import json
        import sys
        from pathlib import Path

        # Load graph
        with open('${{ inputs.output }}', 'r') as f:
            graph = json.load(f)

        # Get changed files
        changed_files = set('$CHANGED_FILES'.split()) if '$CHANGED_FILES' else set()

        # Find affected files
        def get_affected_files(changed_files, graph):
            directly_affected = set()
            transitively_affected = set()
            affected_tests = set()

            # Build dependency map (reverse edges)
            dep_map = {}
            for edge in graph['edges']:
                target = edge['target']
                source = edge['source']
                if target not in dep_map:
                    dep_map[target] = set()
                dep_map[target].add(source)

            # Find directly affected (files that import changed files)
            for changed in changed_files:
                if changed in dep_map:
                    directly_affected.update(dep_map[changed])

            # Find transitively affected (recursive)
            visited = set()
            to_visit = directly_affected.copy()

            while to_visit:
                current = to_visit.pop()
                if current in visited:
                    continue
                visited.add(current)

                if current in dep_map:
                    transitively_affected.update(dep_map[current])
                    to_visit.update(dep_map[current])

            # Find affected tests
            for node in graph['nodes']:
                if node['type'] == 'file' and ('test' in node['name'].lower() or 'spec' in node['name'].lower()):
                    if node['path'] in directly_affected or node['path'] in transitively_affected:
                        affected_tests.add(node['path'])

            return {
                'directly_affected': len(directly_affected),
                'transitively_affected': len(transitively_affected),
                'affected_tests': len(affected_tests),
                'total_affected': len(directly_affected) + len(transitively_affected),
                'changed_files': list(changed_files),
                'directly_affected_files': list(directly_affected)[:5],  # Limit for display
                'transitively_affected_files': list(transitively_affected)[:5]  # Limit for display
            }

        impact = get_affected_files(changed_files, graph)
        print(json.dumps(impact))
        ")

        # Save impact data for later use
        echo "$IMPACT_DATA" > impact_data.json

        # Parse impact data
        DIRECTLY_AFFECTED=$(echo $IMPACT_DATA | jq -r '.directly_affected')
        TRANSITIVELY_AFFECTED=$(echo $IMPACT_DATA | jq -r '.transitively_affected')
        AFFECTED_TESTS=$(echo $IMPACT_DATA | jq -r '.affected_tests')
        TOTAL_AFFECTED=$(echo $IMPACT_DATA | jq -r '.total_affected')

        # Calculate risk level
        TOTAL_FILES=$(jq '.stats.total_nodes' "${{ inputs.output }}")
        AFFECTED_PERCENT=$(( TOTAL_AFFECTED * 100 / TOTAL_FILES ))

        if [ $AFFECTED_PERCENT -gt 50 ]; then
            RISK_LEVEL="critical"
            RISK_EMOJI="üö®"
        elif [ $AFFECTED_PERCENT -gt 20 ]; then
            RISK_LEVEL="high"
            RISK_EMOJI="‚ö†Ô∏è"
        elif [ $AFFECTED_PERCENT -gt 10 ]; then
            RISK_LEVEL="medium"
            RISK_EMOJI="‚ö†Ô∏è"
        elif [ $AFFECTED_PERCENT -gt 5 ]; then
            RISK_LEVEL="low"
            RISK_EMOJI="‚ÑπÔ∏è"
        else
            RISK_LEVEL="minimal"
            RISK_EMOJI="‚úÖ"
        fi

        echo "Risk assessment: $RISK_LEVEL ($AFFECTED_PERCENT% affected)"

        # Save risk data
        echo "{\"risk_level\":\"$RISK_LEVEL\",\"risk_emoji\":\"$RISK_EMOJI\",\"affected_percent\":$AFFECTED_PERCENT,\"directly_affected\":$DIRECTLY_AFFECTED,\"transitively_affected\":$TRANSITIVELY_AFFECTED,\"affected_tests\":$AFFECTED_TESTS}" > risk_data.json
      shell: bash

    - name: Track metrics
      if: inputs.track-metrics == 'true'
      run: |
        # Load current metrics
        NODE_COUNT=$(jq '.stats.total_nodes' "${{ inputs.output }}")
        EDGE_COUNT=$(jq '.stats.total_edges' "${{ inputs.output }}")
        AVG_COMPLEXITY=$(jq '.stats.average_complexity // 0' "${{ inputs.output }}")
        HOT_SPOTS=$(jq '.stats.hot_spots_count // 0' "${{ inputs.output }}")

        # Create metrics data
        METRICS_DATA="{\"timestamp\":\"$(date -u +%Y-%m-%dT%H:%M:%SZ)\",\"nodes\":$NODE_COUNT,\"edges\":$EDGE_COUNT,\"complexity\":$AVG_COMPLEXITY,\"hotspots\":$HOT_SPOTS,\"run_id\":\"${{ github.run_id }}\",\"repository\":\"${{ github.repository }}\"}"

        # Save to metrics file
        echo "$METRICS_DATA" > codex-aura-metrics.json

        # Try to load previous metrics for comparison
        if [ -f "codex-aura-metrics-history.json" ]; then
          PREV_METRICS=$(cat codex-aura-metrics-history.json | jq '.[-1] // empty')
        else
          PREV_METRICS="null"
        fi

        if [ "$PREV_METRICS" != "null" ]; then
          PREV_NODES=$(echo $PREV_METRICS | jq -r '.nodes')
          PREV_EDGES=$(echo $PREV_METRICS | jq -r '.edges')
          PREV_COMPLEXITY=$(echo $PREV_METRICS | jq -r '.complexity')
          PREV_HOTSPOTS=$(echo $PREV_METRICS | jq -r '.hotspots')

          NODES_DIFF=$((NODE_COUNT - PREV_NODES))
          EDGES_DIFF=$((EDGE_COUNT - PREV_EDGES))
          COMPLEXITY_DIFF=$(echo "scale=2; $AVG_COMPLEXITY - $PREV_COMPLEXITY" | bc 2>/dev/null || echo "0")
          HOTSPOTS_DIFF=$((HOT_SPOTS - PREV_HOTSPOTS))

          echo "üìä Trend Analysis:" > trend_summary.txt
          echo "Nodes: $NODE_COUNT (${NODES_DIFF})" >> trend_summary.txt
          echo "Edges: $EDGE_COUNT (${EDGES_DIFF})" >> trend_summary.txt
          echo "Complexity: $AVG_COMPLEXITY (${COMPLEXITY_DIFF})" >> trend_summary.txt
          echo "Hot spots: $HOT_SPOTS (${HOTSPOTS_DIFF})" >> trend_summary.txt
        else
          echo "üìä First metrics collection - no trend data available" > trend_summary.txt
        fi

        # Update metrics history
        if [ -f "codex-aura-metrics-history.json" ]; then
          jq ". + [$METRICS_DATA]" codex-aura-metrics-history.json > temp_metrics.json && mv temp_metrics.json codex-aura-metrics-history.json
        else
          echo "[$METRICS_DATA]" > codex-aura-metrics-history.json
        fi
      shell: bash

    - name: Comment on PR
      if: inputs.comment-on-pr == 'true'
      run: |
        # Get PR number
        PR_NUMBER=$(jq -r '.number' "$GITHUB_EVENT_PATH")

        # Load package results
        if [ -f "package_results.json" ]; then
          PACKAGE_RESULTS=$(cat package_results.json)
          PACKAGE_COUNT=$(echo "$PACKAGE_RESULTS" | jq length)
        else
          PACKAGE_COUNT=1
        fi

        # If multiple packages, create separate comments for each
        if [ "$PACKAGE_COUNT" -gt 1 ]; then
          echo "$PACKAGE_RESULTS" | jq -c '.[]' | while read -r package; do
            PACKAGE_PATH=$(echo "$package" | jq -r '.path')
            PACKAGE_OUTPUT=$(echo "$package" | jq -r '.output')

            # Load package-specific data
            if [ -f "$PACKAGE_OUTPUT" ]; then
              NODE_COUNT=$(jq '.stats.total_nodes' "$PACKAGE_OUTPUT")
              EDGE_COUNT=$(jq '.stats.total_edges' "$PACKAGE_OUTPUT")
              AVG_COMPLEXITY=$(jq '.stats.average_complexity // 0' "$PACKAGE_OUTPUT")
              HOT_SPOTS=$(jq '.stats.hot_spots_count // 0' "$PACKAGE_OUTPUT")
            fi

            # Create package-specific comment
            COMMENT_BODY="## üìä Codex Aura Analysis - $(basename "$PACKAGE_PATH")

### Package: $PACKAGE_PATH

| Metric | Value |
|--------|-------|
| Files | $NODE_COUNT |
| Dependencies | $EDGE_COUNT |
| Complexity | $AVG_COMPLEXITY |
| Hot spots | $HOT_SPOTS |

### Downloads
[Download $(basename "$PACKAGE_PATH") graph](https://github.com/${{ github.repository }}/actions/runs/${{ github.run_id }}/artifacts)"

            # Post comment for this package
            curl -X POST \
              -H "Authorization: token ${{ github.token }}" \
              -H "Accept: application/vnd.github.v3+json" \
              "https://api.com/repos/${{ github.repository }}/issues/$PR_NUMBER/comments" \
              -d "{\"body\":\"$COMMENT_BODY\"}"
          done
        else
          # Single package - use original logic
          # Load impact and risk data
          if [ -f "impact_data.json" ]; then
            IMPACT_DATA=$(cat impact_data.json)
          fi

          if [ -f "risk_data.json" ]; then
            RISK_DATA=$(cat risk_data.json)
            RISK_LEVEL=$(echo $RISK_DATA | jq -r '.risk_level')
            RISK_EMOJI=$(echo $RISK_DATA | jq -r '.risk_emoji')
            DIRECTLY_AFFECTED=$(echo $RISK_DATA | jq -r '.directly_affected')
            TRANSITIVELY_AFFECTED=$(echo $RISK_DATA | jq -r '.transitively_affected')
            AFFECTED_TESTS=$(echo $RISK_DATA | jq -r '.affected_tests')
          fi

          # Get affected files lists
          if [ -n "$IMPACT_DATA" ]; then
            DIRECTLY_AFFECTED_FILES=$(echo $IMPACT_DATA | jq -r '.directly_affected_files[]' | head -5 | sed 's/^/- /' | tr '\n' '\n')
            TRANSITIVELY_AFFECTED_FILES=$(echo $IMPACT_DATA | jq -r '.transitively_affected_files[]' | head -5 | sed 's/^/- /' | tr '\n' '\n')
            CHANGED_FILES_LIST=$(echo $IMPACT_DATA | jq -r '.changed_files[]' | sed 's/^/- /' | tr '\n' '\n')
          fi

          # Load trend data if available
          TREND_INFO=""
          if [ -f "trend_summary.txt" ]; then
            TREND_INFO=$(cat trend_summary.txt)
          fi

          # Create comment body
          COMMENT_BODY="## üìä Codex Aura Analysis

### Changed Files
$CHANGED_FILES_LIST

### Impact Assessment

| Metric | Value |
|--------|-------|
| Directly affected files | $DIRECTLY_AFFECTED |
| Transitively affected | $TRANSITIVELY_AFFECTED |
| Affected tests | $AFFECTED_TESTS |
| Risk level | $RISK_EMOJI $RISK_LEVEL |

### Affected Files
<details>
<summary>Show directly affected files ($DIRECTLY_AFFECTED)</summary>

$DIRECTLY_AFFECTED_FILES
</details>

<details>
<summary>Show transitively affected files ($TRANSITIVELY_AFFECTED)</summary>

$TRANSITIVELY_AFFECTED_FILES
</details>

### Trend Analysis
$TREND_INFO

### Downloads
[Download full graph](https://github.com/${{ github.repository }}/actions/runs/${{ github.run_id }}/artifacts)"

          # Post comment using GitHub API
          curl -X POST \
            -H "Authorization: token ${{ github.token }}" \
            -H "Accept: application/vnd.github.v3+json" \
            "https://api.github.com/repos/${{ github.repository }}/issues/$PR_NUMBER/comments" \
            -d "{\"body\":\"$COMMENT_BODY\"}"
        fi
      shell: bash

    - name: Upload artifact
      if: inputs.upload-artifact == 'true'
      uses: actions/upload-artifact@v4
      with:
        name: ${{ inputs.artifact-name }}
        path: ${{ inputs.output }}
        retention-days: ${{ inputs.artifact-retention-days }}

    - name: Upload metrics artifact
      if: inputs.track-metrics == 'true'
      uses: actions/upload-artifact@v4
      with:
        name: ${{ inputs.artifact-name }}-metrics
        path: |
          codex-aura-metrics.json
          codex-aura-metrics-history.json
        retention-days: ${{ inputs.artifact-retention-days }}

    - name: Risk-based blocking
      if: inputs.fail-on-risk != 'none'
      run: |
        # Load risk data
        if [ -f "risk_data.json" ]; then
          RISK_DATA=$(cat risk_data.json)
          RISK_LEVEL=$(echo $RISK_DATA | jq -r '.risk_level')
          AFFECTED_PERCENT=$(echo $RISK_DATA | jq -r '.affected_percent')
          TOTAL_AFFECTED=$(echo $RISK_DATA | jq -r '.directly_affected + .transitively_affected')
          TOTAL_FILES=$(jq '.stats.total_nodes' "${{ inputs.output }}")
        fi

        # Determine if we should fail based on risk level
        SHOULD_FAIL=false

        case ${{ inputs.fail-on-risk }} in
          "low")
            if [ "$RISK_LEVEL" = "low" ] || [ "$RISK_LEVEL" = "medium" ] || [ "$RISK_LEVEL" = "high" ] || [ "$RISK_LEVEL" = "critical" ]; then
              SHOULD_FAIL=true
            fi
            ;;
          "medium")
            if [ "$RISK_LEVEL" = "medium" ] || [ "$RISK_LEVEL" = "high" ] || [ "$RISK_LEVEL" = "critical" ]; then
              SHOULD_FAIL=true
            fi
            ;;
          "high")
            if [ "$RISK_LEVEL" = "high" ] || [ "$RISK_LEVEL" = "critical" ]; then
              SHOULD_FAIL=true
            fi
            ;;
          "critical")
            if [ "$RISK_LEVEL" = "critical" ]; then
              SHOULD_FAIL=true
            fi
            ;;
        esac

        if [ "$SHOULD_FAIL" = "true" ]; then
          echo "‚ùå PR blocked due to $RISK_LEVEL risk level (threshold: ${{ inputs.fail-on-risk }})"
          echo "Affected files: $TOTAL_AFFECTED/$TOTAL_FILES ($AFFECTED_PERCENT%)"
          echo "::error::PR blocked: Risk level $RISK_LEVEL exceeds threshold ${{ inputs.fail-on-risk }}"
          exit 1
        else
          echo "‚úÖ PR approved: Risk level $RISK_LEVEL is below threshold ${{ inputs.fail-on-risk }}"
        fi
      shell: bash